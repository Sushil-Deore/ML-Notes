{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression \n",
    "\n",
    "### 1.  what is Learning methods? Where we use supervised and unsupervised\n",
    "#### Answer:\n",
    "- Supervised and unsupervised learning methods \n",
    "- Supervised learning allows collecting data and produces data output from previous experiences. It helps to optimize performance critieria with the help of expierence.\n",
    "- Supervised machine learning is the machine learning task of learning a function that maps an input to an output based on example input-output pair.\n",
    "- Unsupervised learning is a type of algorithum that learns patterns from untagged data. \n",
    "- Unsupervised machine learning allows the model to work on its own to discover patterns and information that was previously undetected. It mainly deals with the unlabelled data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  what is residuals?\n",
    "#### Answer:\n",
    "- the differences between observed and predicted values of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. What is OLS ? why we use OLS ?\n",
    "#### Answer:\n",
    "- The OLS estimator is one that has a minimum variance. This property is simply a way to determine which estimator to use. - An estimator that is unbiased but does not have the minimum variance is not good. \n",
    "- An estimator that is unbiased and has the minimum variance of all other estimators is the best (efficient).\n",
    "- OLS estimators minimize the sum of the squared errors (a difference between observed values and predicted values).\n",
    "\n",
    "`formula : beta_hat = (((X^T* X)^-1)X^T)y`\n",
    "\n",
    "- In statistics, ordinary least squares (OLS) is a type of linear least squares method for estimating the unknown parameters in a linear regression model. Under these conditions, the method of OLS provides minimum-variance mean-unbiased estimation when the errors have finite variances.\n",
    "- OLS is concerned with the squares of the errors. It tries to find the line going through the sample data that minimizes the sum of the squared errors.\n",
    "- The goal of OLS is to closely \"fit\" a function with the data. It does so by minimizing the sum of squared errors from the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. What is RSS?\n",
    "#### Answer:\n",
    "- A residual sum of squares (RSS) is a statistical technique used to measure the amount of variance in a data set that is not explained by a regression model itself.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. What is Gradient descent?\n",
    "#### Answer:\n",
    "- Gradient descent is an optimization algorithm that's used when training a machine learning model. It's based on a convex function and tweaks its parameters iteratively to minimize a given function to its local minimum.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.  What is TSS?\n",
    "#### Answer:\n",
    "- TSS is the sum of square of difference of each data point from the mean value of all the values of target variable (y).  - If the predicted line can explain each data point correctly then the difference between actual and predicted is 0 which means that RSS is 0 and hence, R2 is 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.  Strength of simple linear regression?\n",
    "#### Answer:\n",
    "- Simple linear regression relates X to Y through an equation of the form Y = a + bX. Both quantify the direction and strength of the relationship between two numeric variables.\n",
    "- Positive r indicates positive association between the variables, and negative r indicates negative association. \n",
    "- The correlation r is always a number between −1 and 1. Values of r near 0 indicate a very weak linear relationship. \n",
    "- The strength of the relationship increases as r moves away from 0 toward either −1 or 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.  What is R-squared?\n",
    "#### Answer:\n",
    "- R-squared is a goodness-of-fit measure for linear regression models. \n",
    "- R-squared measures the strength of the relationship between your model and the dependent variable on a convenient 0 – 100% scale. \n",
    "- After fitting a linear regression model, you need to determine how well the model fits the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. What is RSE? (Residual Squared Error)\n",
    "#### Answer:\n",
    "- Residual squared error is (RSS/df) where, df = n-2 & n = number of data points.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. what is variance?\n",
    "#### Answer:\n",
    "- The variance is a measure of variability. \n",
    "- It is calculated by taking the average of squared deviations from the mean. \n",
    "- Variance tells you the degree of spread in your data set. The more spread the data, the larger the variance is in relation to the mean.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. what is covariance?\n",
    "#### Answer:\n",
    "- Covariance provides insight into how two variables are related to one another. \n",
    "- More precisely, covariance refers to the measure of how two random variables in a data set will change together. \n",
    "- A positive covariance means that the two variables at hand are positively related, and they move in the same direction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. what is Bias?\n",
    "#### Answer:\n",
    "- Data bias in machine learning is a type of error in which certain elements of a dataset are more heavily weighted and/or represented than others. \n",
    "- A biased dataset does not accurately represent a model's use case, resulting in skewed outcomes, low accuracy levels, and analytical errors.\n",
    "                     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. what is correlation?\n",
    "#### Answer:\n",
    "- Correlation is a measure of how strongly one variable depends on another.\n",
    "- We can plot correlation matrix to show which variable is having a high or low correlation in respect to another variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. What is cost function?\n",
    "#### Answer:\n",
    "- It is a function that measures the performance of a Machine Learning model for given data. \n",
    "- Cost Function quantifies the error between predicted values and expected values and presents it in the form of a single real number.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. What is cost function for Linear regression?\n",
    "#### Answer:\n",
    "- A cost function is a measure of how wrong the model is in terms of its ability to estimate the relationship between X and y. \n",
    "- This is typically expressed as a difference or distance between the predicted value and the actual value. \n",
    "- The cost function (you may also see this referred to as loss or error.)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. what are optimisation methods?\n",
    "#### Answer:\n",
    "- The goal of optimization methods is to find an optimal or near-optimal solution with low computational effort.\n",
    "- Optimization is the problem of finding a set of inputs to an objective function that results in a maximum or minimum function evaluation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. what contribute the bias in linear regression?\n",
    "#### Answer:\n",
    "- A linear regression model would have high bias when trying to model a non-linear relationship. \n",
    "- It is because linear regression model does not fit non-linear relationship well.\n",
    "- Low bias means second degree polynomial applied to quadratic data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. what is learning rate in linear regression?\n",
    "#### Answer:\n",
    "- Learning rate gives the rate of speed where the gradient moves during gradient descent. \n",
    "- Setting it too high would make your path instable, too low would make convergence slow. \n",
    "- Put it to zero means your model isn't learning anything from the gradients.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. what is variability?\n",
    "#### Answer:\n",
    "- Variability, almost by definition, is the extent to which data points in a statistical distribution or data set diverge—vary—from the average value, as well as the extent to which these data points differ from each other.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. What are assumptions of simple linear regression?\n",
    "#### Answer:\n",
    "- Linear relationship: There exists a linear relationship between the independent variable, x, and the dependent variable, y.\n",
    "- Independence: The residuals are independent.\n",
    "- Homoscedasticity: The residuals have constant variance at every level of x.\n",
    "- Normality: The residuals of the model are normally distributed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. why we have assumptions for simple linear regression?\n",
    "#### Answer:\n",
    "- If any of these assumptions is violated (i.e., if there are nonlinear relationships between dependent and independent variables or the errors exhibit correlation, heteroscedasticity, or non-normality), then the forecasts, confidence intervals, and scientific insights yielded by a regression model may be (at best) inefficient or (at worst) seriously biased or misleading.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. Explain 1st assumption of linear regression?\n",
    "#### Answer:\n",
    "- First, linear regression needs the relationship between the independent and dependent variables to be linear.  \n",
    "- It is also important to check for outliers since linear regression is sensitive to outlier effects.  \n",
    "- The linearity assumption can best be tested with scatter plots.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23. Explain 2nd assumption of linear regression?\n",
    "#### Answer:\n",
    "- Secondly, the linear regression analysis requires all variables to be multivariate normal.  \n",
    "- This assumption can best be checked with a histogram or a Q-Q-Plot.  \n",
    "- Normality can be checked with a goodness of fit test. When the data is not normally distributed a non-linear transformation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24. Explain 3rd assumption of linear regression?\n",
    "#### Answer:\n",
    "- Thirdly, linear regression assumes that there is little or no multicollinearity in the data.  \n",
    "- Multicollinearity occurs when the independent variables are too highly correlated with each other.\n",
    "1. Correlation matrix\n",
    "2. Variance Inflation Factor (VIF)\n",
    "- If multicollinearity is found in the data, centering the data (that is deducting the mean of the variable from each score) might help to solve the problem.  However, the simplest way to address the problem is to remove independent variables with high VIF values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25. Explain 4th assumption of linear regression?\n",
    "#### Answer:\n",
    "- Fourth, linear regression analysis requires that there is little or no autocorrelation in the data.  \n",
    "- Autocorrelation occurs when the residuals are not independent from each other.  \n",
    "- For instance, this typically occurs in stock prices, where the price is not independent from the previous price.\n",
    "- Autocorrelation occurs when the residuals are not independent from each other.  \n",
    "- In other words when the value of y(x+1) is not independent from the value of y(x).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 26. what do you mean by constant variance? (homoscedasticity)\n",
    "#### Answer:\n",
    "- It means that when you plot the individual error against the predicted value, the variance of the error predicted value should be constant.\n",
    "- The variance is a measure of variability. It is calculated by taking the average of squared deviations from the mean. Variance tells you the degree of spread in your data set. The more spread the data, the larger the variance is in relation to the mean.\n",
    "- The assumption of equal variances (i.e. assumption of homoscedasticity) assumes that different samples have the same variance, even if they came from different populations. The assumption is found in many statistical tests, including Analysis of Variance (ANOVA) and Student's T-Test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27. What is heteroscedasticity? What are the consequences, and how can you overcome it?\n",
    "#### Answer:\n",
    "- A random variable is said to be heteroscedastic when different subpopulations have different variabilities (standard deviation).\n",
    "- The existence of heteroscedasticity gives rise to certain problems in the regression analysis as the assumption says that error terms are uncorrelated and, hence, the variance is constant. The presence of heteroscedasticity can often be seen in the form of a cone-like scatter plot for residual vs fitted values.\n",
    "- One of the basic assumptions of linear regression is that the data should be homoscedastic, i.e., heteroscedasticity is not present in the data. Due to the violation of assumptions, the ordinary least squares (OLS) estimators are not the Best Linear Unbiased Estimators (BLUE). Hence, they do not give a lesser variance than other Linear Unbiased Estimators (LUEs).\n",
    "- There is no fixed procedure to overcome heteroscedasticity. However, there are some ways that may lead to a reduction of heteroscedasticity. They are:\n",
    "    - Logarithmising the data: A series that is increasing exponentially often results in increased variability. This can be overcome using the log transformation.\n",
    "    - Using weighted linear regression: Here, the OLS method is applied to the weighted values of X and Y. One way is to attach weights directly related to the magnitude of the dependent variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28. What is Hypothesis testing in linear regression?\n",
    "#### Answer:\n",
    "- Hypothesis testing can be carried out in linear regression for the following purposes:\n",
    "    - To check whether a predictor is significant for the prediction of the target variable. Two common methods for this are as follows:\n",
    "    - By the use of p-values:\n",
    "        - If the p-value of a variable is greater than a certain limit (usually 0.05), the variable is insignificant in the prediction of the target variable.\n",
    "        - By checking the values of the regression coefficient:\n",
    "            - If the value of the regression coefficient corresponding to a predictor is zero, that variable is insignificant in the prediction of the target variable and has no linear relationship with it.\n",
    "            - To check whether the calculated regression coefficients are good estimators of the actual coefficients.\n",
    "            - The null and alternative hypotheses used in the case of linear regression, respectively, are:\n",
    "                β1 = 0\n",
    "                β1 ≠ 0\n",
    "             Thus, if we reject the null hypothesis, we can say that the coefficient β1 is not equal to zero and, hence, is significant for the model. On the other hand, if we fail to reject the null hypothesis, we can conclude that the coefficient is insignificant and should be dropped from the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 29. what is t-score?\n",
    "#### Answer:\n",
    "- This score is simply the ratio between the mean difference across two groups, as well as the difference within the groups. \n",
    "- The bigger the t score, the larger the difference between samples, which also means the test results are more likely reproducible\n",
    "- Higher values of the t-value, also called t-score, indicate that a large difference exists between the two sample sets. - - The smaller the t-value, the more similarity exists between the two sample sets. \n",
    "- A large t-score indicates that the groups are different. A small t-score indicates that the groups are similar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30. what is z- score?\n",
    "#### Answer:\n",
    "- The z score (also called the standard score) represents the number of standard deviations with which the value of an observation point or data differ than the mean value of what is observed.\n",
    "-  In other words it merely re-scales, or standardizes, your data. A Z-score serves to specify the precise location of each observation within a distribution.\n",
    "- If a z-score is equal to 0, it is on the mean. If a Z-Score is equal to +1, it is 1 Standard Deviation above the mean. \n",
    "- If a z-score is equal to +2, it is 2 Standard Deviations above the mean. This means that raw score of 98% is pretty darn good relative to the rest of the students in your class.\n",
    "-  z-scores are particularly helpful in comparing observations that come from different populations and from distributions with different means, standard deviations.\n",
    "- A z-score has meaning only if it is calculated for observations that are part of a normal distribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 31. what is standard error?\n",
    "#### Answer:\n",
    "- The standard error of the regression (S), also known as the standard error of the estimate, represents the average distance that the observed values fall from the regression line. \n",
    "- Conveniently, it tells you how wrong the regression model is on average using the units of the response variable.\n",
    "- To reduce standard error in regression:\n",
    "        - Increase the sample size. Often, the most practical way to decrease the margin of error is to increase the sample size. \n",
    "        - Reduce variability. The less that your data varies, the more precisely you can estimate a population parameter. \n",
    "        - Use a one-sided confidence interval. \n",
    "        - Lower the confidence level.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 32. what is p-value? \n",
    "#### Answer:\n",
    "- The p-value, or probability value, tells you how likely it is that your data could have occurred under the null hypothesis.\n",
    "- The p-value is a proportion: if your p-value is 0.05, that means that 5% of the time you would see a test statistic at least as extreme as the one you found if the null hypothesis was true.\n",
    "- The smaller the p-value, the stronger the evidence that you should reject the null hypothesis.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 33. what is significance of t-value?\n",
    "#### Answer:\n",
    "- The t-value measures the size of the difference relative to the variation in your sample data. \n",
    "- Put another way, T is simply the calculated difference represented in units of standard error. \n",
    "- The greater the magnitude of T, the greater the evidence against the null hypothesis.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 34. what is significance of z-value?\n",
    "#### Answer:\n",
    "- The Z-value is a test statistic for Z-tests that measures the difference between an observed statistic and its hypothesized population parameter in units of the standard deviation.\n",
    "- Converting an observation to a Z-value is called standardization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 35. what is significance of p-value?\n",
    "#### Answer:\n",
    "- The smaller the p-value, the stronger the evidence that you should reject the null hypothesis. \n",
    "- A p-value less than 0.05 (typically ≤ 0.05) is statistically significant. \n",
    "- It indicates strong evidence against the null hypothesis, as there is less than a 5% probability the null is correct (and the results are random).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 36. what is significance of standard error?\n",
    "#### Answer:\n",
    "- Standard error statistics measure how accurate and precise the sample is as an estimate of the population parameter. \n",
    "- It is particularly important to use the standard error to estimate an interval about the population parameter when an effect size statistic is not available.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 37. Read library info for statsmodels, sklearn\n",
    "#### Answer:\n",
    "- statsmodels : statsmodels is a Python package that provides a complement to scipy for statistical computations including descriptive statistics and estimation and inference for statistical models.\n",
    "- sklearn : Scikit-learn is a free software machine learning library for the Python programming language. It features various classification, regression and clustering algorithms including support vector machines, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 38. Read library info for pandas, numpy\n",
    "#### Answer:\n",
    "- pandas : pandas is a software library written for the Python programming language for data manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and time series.\n",
    "- Numpy : NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 39. Read library info for matplotlib, seaborn\n",
    "#### Answer:\n",
    "- matplotlib : Matplotlib is a plotting library for the Python programming language and its numerical mathematics extension NumPy. It provides an object-oriented API for embedding plots into applications using general-purpose GUI toolkits like Tkinter, wxPython, Qt, or GTK.\n",
    "- seaborn : Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 40. what do you mean by instantiating object?\n",
    "#### Answer:\n",
    "\n",
    " - In programming, instantiation is the creation of a real instance or particular realization of an abstraction or template such as a class of objects or a computer process. To instantiate is to create such an instance by, for example, defining one particular variation of object within a class, giving it a name, and locating it in some physical place.\n",
    "\n",
    "    1) In object-oriented programming, some writers say that you instantiate a class to create an object, a concrete instance of the class. The object is an executable file that you can run in a computer.\n",
    "\n",
    "    2) In the object-oriented programming language, Java, the object that you instantiate from a class is, confusingly enough, called a class instead of an object. In other words, using Java, you instantiate a class to create a specific class that is also an executable file you can run in a computer.\n",
    "\n",
    "    3) In approaches to data modeling and programming prior to object-oriented programming, one usage of instantiate was to make a real (data-filled) object from an abstract object as you would do by creating an entry in a database table (which, when empty, can be thought of as a kind of class template for the objects to be filled in).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 41. what does \".fit\" do to the model?\n",
    "#### Answer:\n",
    "- There is a fit function in ML, that is used for training of model using data examples. \n",
    "- Fit function adjusts weights according to data values so that better accuracy can be achieved. \n",
    "- After training, the model can be used for predictions, using . predict() method call.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 42. what does\".fit_transform\" do to the model?\n",
    "#### Answer:\n",
    "- fit_transform() joins these two steps and is used for the initial fitting of parameters on the training set x, while also returning the transformed x′. \n",
    "- Internally, the transformer object just calls first fit() and then transform() on the same data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 43. what does \".transform\" do to the model?\n",
    "#### Answer:\n",
    "- Python's Transform function returns a self-produced dataframe with transformed values after applying the function specified in its parameter. This dataframe has the same length as the passed dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 44. what is F-statistics?\n",
    "#### Answer:\n",
    "- The test statistic in an F-test is the ratio of two scaled sums of squares reflecting different sources of variability.\n",
    "- An F-test is any statistical test in which the test statistic has an F-distribution under the null hypothesis. \n",
    "- It is most often used when comparing statistical models that have been fitted to a data set, in order to identify the model that best fits the population from which the data were sampled.\n",
    "- The F-statistic is the test statistic for F-tests. In general, an F-statistic is a ratio of two quantities that are expected to be roughly equal under the null hypothesis, which produces an F-statistic of approximately 1.\n",
    "- In order to reject the null hypothesis that the group means are equal, we need a high F-value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 45. What is RMSE?\n",
    "#### Answer:\n",
    "- Root Mean Square Error is the measure of how well a regression line fits the data points. \n",
    "- RMSE can also be construed as Standard Deviation in the residuals.\n",
    "- The RMSE is a quadratic scoring rule which measures the average magnitude of the error. Since the errors are squared before they are averaged, the RMSE gives a relatively high weight to large errors. This means the RMSE is most useful when large errors are particularly undesirable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 46. what is relative mesure & absolute measure?\n",
    "#### Answer:\n",
    "- An absolute measure is one that uses numerical variations to determine the degree of error.\n",
    "- Relative measures are the major alternative to absolute measures. They use statistical variations based on percentages to determine how far from reality a figure is within context.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 47. How do you check the significance of fit?\n",
    "#### Answer:\n",
    "- In general, a model fits the data well if the differences between the observed values and the model's predicted values are small and unbiased. Before you look at the statistical measures for goodness-of-fit, you should check the residual plots.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 48. How do you check hyperplane fit on data?\n",
    "#### Answer:\n",
    "- When we fit the model what we're really doing is choosing the values for m and b – the slope and the intercept. \n",
    "- The point of fitting the model is to find this equation – to find the values of m and b such that `y=mx+b` describes a line that fits our observed data well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 49. How do you fit a hyperplane on 3 variables?\n",
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50. What is overfitting?\n",
    "#### Answer:\n",
    "- Overfitting refers to a model that models the training data too well. \n",
    "- Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 51. What is underfitting?\n",
    "#### Answer:\n",
    "- Underfitting refers to a model that can neither model the training data nor generalize to new data. \n",
    "- An underfit machine learning model is not a suitable model and will be obvious as it will have poor performance on the training data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 52. What is multicollinearity?\n",
    "#### Answer:\n",
    "- Multicollinearity occurs when two or more independent variables are highly correlated with one another in a regression model. \n",
    "- This means that an independent variable can be predicted from another independent variable in a regression model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 53. effect of multicollinearity?\n",
    "#### Answer:\n",
    "- This will lead to overfitting where the model may do great on known training set but will fail at unknown testing set. \n",
    "- As this leads to higher standard error with lower statistical significance value, multicollinearity makes it difficult to ascertain how important a feature is to the target variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 54. What is VIF?\n",
    "#### Answer:\n",
    "- Variance Inflation Factor (VIF) is used to detect the presence of multicollinearity. \n",
    "- Variance inflation factors (VIF) measure how much the variance of the estimated regression coefficients are inflated as compared to when the predictor variables are not linearly related.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 55. How to deal with multicollinearity?\n",
    "#### Answer:\n",
    "- Remove some of the highly correlated independent variables.\n",
    "- Linearly combine the independent variables, such as adding them together.\n",
    "- Perform an analysis designed for highly correlated variables, such as principal components analysis or partial least squares regression.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 56. What is dummy variables?\n",
    "#### Answer:\n",
    "- A dummy variable is a variable that takes values of 0 and 1, where the values indicate the presence or absence of something (e.g., a 0 may indicate a placebo and 1 may indicate a drug).\n",
    "- Dummy variables are also known as indicator variables, design variables, contrasts, one-hot coding, and binary basis variables.\n",
    "- Dummy variables are useful because they enable us to use a single regression equation to represent multiple groups. This means that we don't need to write out separate equation models for each subgroup. The dummy variables act like 'switches' that turn various parameters on and off in an equation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 57.How do you decide number of dummy variable?\n",
    "#### Answer:\n",
    "- The first step in this process is to decide the number of dummy variables. This is easy; it's simply k-1, where k is the number of levels of the original variable. \n",
    "- You could also create dummy variables for all levels in the original variable, and simply drop one from each analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 58. How does Standardisation work?\n",
    "#### Answer:\n",
    "- In statistics, standardization is the process of putting different variables on the same scale. \n",
    "- Typically, to standardize variables, you calculate the mean and standard deviation for a variable. Then, for each observed value of the variable, you subtract the mean and divide by the standard deviation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 59. How does MinMaxScaler works?\n",
    "#### Answer:\n",
    "- Transform features by scaling each feature to a given range. \n",
    "- This estimator scales and translates each feature individually such that it is in the given range on the training set, e.g. between zero and one. where min, max = feature_range.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 60. Why it's necessary to create dummy variables\n",
    "#### Answer:\n",
    "- Dummy variables are useful because they enable us to use a single regression equation to represent multiple groups. \n",
    "- This means that we don't need to write out separate equation models for each subgroup. \n",
    "- The dummy variables act like 'switches' that turn various parameters on and off in an equation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 61. When to normalise data and when to standardise\n",
    "#### Answer:\n",
    "- Normalization is useful when your data has varying scales and the algorithm you are using does not make assumptions about the distribution of your data, such as k-nearest neighbors and artificial neural networks. \n",
    "- Normalization typically means rescales the values into a range of [0,1]\n",
    "\n",
    "\n",
    "- Standardization assumes that your data has a Gaussian (bell curve) distribution.\n",
    "- Standardization typically means rescales data to have a mean of 0 and a standard deviation of 1 (unit variance).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 62. various scaling techniques?\n",
    "#### Answer:\n",
    "- Standardization. It is also called Z-score normalization.\n",
    "- Min-Max Scaling: It is also referred to as Normalization.\n",
    "- Binarizing. It is used for binary thresholding of an array like matrix.\n",
    "- Normalizing. It is used to rescale each sample.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 63. How do you assess the model? or what is model evaluation?\n",
    "#### Answer:\n",
    "- Model Evaluation is an integral part of the model development process. \n",
    "- It helps to find the best model that represents our data and how well the chosen model will work in the future. \n",
    "- To avoid overfitting, both methods use a test set (not seen by the model) to evaluate model performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 64. What is adj. R-squared?\n",
    "#### Answer:\n",
    "- The adjusted R-squared is a modified version of R-squared that adjusts for predictors that are not significant in a regression model. \n",
    "- Compared to a model with additional input variables, a lower adjusted R-squared indicates that the additional input variables are not adding value to the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 65. Why we need Adj. R-Squared?\n",
    "#### Answer:\n",
    "- The Adjusted R-squared takes into account the number of independent variables used for predicting the target variable. \n",
    "- In doing so, we can determine whether adding new variables to the model actually increases the model fit.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 66. What is feature selection?\n",
    "#### Answer:\n",
    "- Feature selection is the process of reducing the number of input variables when developing a predictive model. \n",
    "- Filter-based feature selection methods use statistical measures to score the correlation or dependence between input variables that can be filtered to choose the most relevant features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 67. What is RFE? \n",
    "#### Answer:\n",
    "- Recursive Feature Elimination, or RFE for short, is a popular feature selection algorithm.\n",
    "- RFE is popular because it is easy to configure and use and because it is effective at selecting those features (columns) in a training dataset that are more or most relevant in predicting the target variable.\n",
    "\n",
    "- There are two important configuration options when using RFE: the choice in the number of features to select and the choice of the algorithm used to help choose features. Both of these hyperparameters can be explored, although the performance of the method is not strongly dependent on these hyperparameters being configured well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 68. How RFE Works?\n",
    "#### Answer:\n",
    "- Recursive feature elimination (RFE) is a feature selection method that fits a model and removes the weakest feature (or features) until the specified number of features is reached. \n",
    "- RFE requires a specified number of features to keep, however it is often not known in advance how many features are valid.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 69. What is Boxplot?\n",
    "#### Answer:\n",
    "- A box plot is a method for graphically depicting groups of numerical data through their quartiles. The box extends from the Q1 to Q3 quartile values of the data, with a line at the median (Q2). \n",
    "- The whiskers extend from the edges of box to show the range of the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 70. What is IQR?\n",
    "#### Answer:\n",
    "- The interquartile range is the difference between the upper quartile and the lower quartile. \n",
    "- In example 1, the IQR = Q3 – Q1 = 87 - 52 = 35. \n",
    "- The IQR is a very useful measurement. It is useful because it is less influenced by extreme values as it limits the range to the middle 50% of the values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 71. what is mapping?\n",
    "#### Answer: \n",
    "- Python's map() is a built-in function that allows you to process and transform all the items in an iterable without using an explicit for loop, a technique commonly known as mapping. \n",
    "- map() is useful when you need to apply a transformation function to each item in an iterable and transform them into a new iterable.\n",
    "\n",
    "### 72. When do you do mapping?\n",
    "#### Answer:\n",
    "- When we have multiple levels of categorical data which represents order.\n",
    "\n",
    "### 73. What is training error?\n",
    "#### Answer:\n",
    "- Training Error: We get the by calculating the classification error of a model on the same data the model was trained on.\n",
    "- Training error is the error that you get when you run the trained model back on the training data. \n",
    "- Remember that this data has already been used to train the model and this necessarily doesn't mean that the model once trained will accurately perform when applied back on the training data itself.\n",
    "\n",
    "### 74. What is testing error?\n",
    "#### Answer:\n",
    "- Test Error: We get this by using two completely disjoint datasets: one to train the model and the other to calculate the classification error. Both datasets need to have values for y. The first dataset is called training data and the second, test data.\n",
    "- Test error is the error when you get when you run the trained model on a set of data that it has previously never been exposed to. \n",
    "- This data is often used to measure the accuracy of the model before it is shipped to production.\n",
    "\n",
    "### 75. How do you deal with tranining error?\n",
    "#### Answer:\n",
    "\n",
    "### 76. How do you deal with test error?\n",
    "#### Answer:\n",
    "\n",
    "### 77. What is parametric model?\n",
    "#### Answer:\n",
    "- In a parametric model, the number of parameters is fixed with respect to the sample size.\n",
    "- The following are five different examples of parametric models: \n",
    "    - exponential distributions, \n",
    "    - poisson distributions, \n",
    "    - normal distributions, \n",
    "    - the Weibull distribution, \n",
    "    - linear regressions.\n",
    "    \n",
    "- Parametric Methods uses a fixed number of parameters to build the model.\n",
    "- Parametric analysis is to test group means.\n",
    "- It is applicable only for variables.\n",
    "- It always considers strong assumptions about data.\n",
    "- Parametric Methods require lesser data than Non-Parametric Methods.\n",
    "- Parametric methods assumed to be a normal distribution.\n",
    "- Parametric data handles – Intervals data or ratio data.\n",
    "- Here when we use parametric methods then the result or outputs generated can be easily affected by outliers.\n",
    "- Parametric Methods can perform well in many situations but its performance is at peak (top) when the spread of each group is different.\n",
    "- Parametric methods have more statistical power than Non-Parametric methods.\n",
    "- As far as the computation is considered these methods are computationally faster than the Non-Parametric methods.\n",
    "- Examples – Logistic Regression, Naïve Bayes Model, etc.\n",
    "\n",
    "### 78. what is non-parametric model?\n",
    "#### Answer:\n",
    "- In a nonparametric model, the (effective) number of parameters can grow with the sample size.\n",
    "- Algorithms that do not make strong assumptions about the form of the mapping function are called nonparametric machine learning algorithms. By not making assumptions, they are free to learn any functional form from the training data.\n",
    "\n",
    "- Non-Parametric Methods use the flexible number of parameters to build the model.\n",
    "- A non-parametric analysis is to test medians.\n",
    "- It is applicable for both – Variable and Attribute.\n",
    "- It generally fewer assumptions about data.\n",
    "- Non-Parametric Methods requires much more data than Parametric Methods.\n",
    "- There is no assumed distribution in non-parametric methods.\n",
    "- But non-parametric methods handle original data.\n",
    "- When we use non-parametric methods then the result or outputs generated cannot be seriously affected by outliers.\n",
    "- Similarly, Non-Parametric Methods can perform well in many situations but its performance is at peak (top) when the spread of each group is the same.\n",
    "- Non-parametric methods have less statistical power than Parametric methods.\n",
    "- As far as the computation is considered these methods are computationally faster than the Parametric methods.\n",
    "- Examples – KNN, Decision Tree Model, etc.\n",
    "\n",
    "\n",
    "### 79. What is Prediction?\n",
    "#### Answer:\n",
    "- Prediction is concerned with estimating the outcomes for unseen data.\n",
    "\n",
    "### 80. What is Projection?\n",
    "#### Answer:\n",
    "- Forecasting is a sub-discipline of prediction in which we are making predictions about the future, on the basis of time-series data. Thus, the only difference between prediction and forecasting is that we consider the temporal dimension.\n",
    "\n",
    "### 81. Where is regression use?\n",
    "#### Answer:\n",
    "- Three major uses for regression analysis are \n",
    "    (1) determining the strength of predictors, \n",
    "    (2) forecasting an effect, and \n",
    "    (3) trend forecasting. First, the regression might be used to identify the strength of the effect that the independent variable(s) have on a dependent variable.\n",
    "\n",
    "### 82. What is EDA?\n",
    "#### Answer:\n",
    "- Exploratory data analysis is an approach to analyzing data sets to summarize their main characteristics, often using statistical graphics and other data visualization methods\n",
    "\n",
    "### 83. What is Univariate analysis?\n",
    "#### Answer:\n",
    "- Univariate analysis is perhaps the simplest form of statistical analysis. Like other forms of statistics, it can be inferential or descriptive. The key fact is that only one variable is involved.\n",
    "\n",
    "### 84. What is bivariate analysis?\n",
    "#### Answer:\n",
    "- Bivariate analysis is one of the simplest forms of quantitative analysis. \n",
    "- It involves the analysis of two variables, for the purpose of determining the empirical relationship between them.\n",
    "\n",
    "### 85. what is multivariate analysis?\n",
    "#### Answer:\n",
    "- Multivariate analysis is based on the principles of multivariate statistics, which involves observation and analysis of more than one statistical outcome variable at a time.\n",
    "\n",
    "### 86. What are the shortcomings of linear regression?\n",
    "#### Answer:\n",
    "- We are only considering LINEAR relationships.\n",
    "- r and least squares regression are NOT resistant to outliers\n",
    "- There may be variables other than x which are not studied, yet do influence the response variable.\n",
    "- A strong correlation does NOT imply cause and effect relationship.\n",
    "- Extrapolation is dangerous.\n",
    "\n",
    "### 87. What parameters are used to check the significance of the model and the goodness of fit?\n",
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 88. What is the difference between least squares error and mean squared error?\n",
    "#### Answer:\n",
    "\n",
    "### 89. What is OneHot Encoding?\n",
    "#### Answer:\n",
    "\n",
    "### 90. What is label encodeer?\n",
    "#### Answer:\n",
    "\n",
    "### 91. Where we use OneHot encoding and where we use label encoding?\n",
    "#### Answer:\n",
    "\n",
    "### 92. What is the major difference between R-squared and adjusted R-squared? Or, why is it advised to use adjusted R-squared in case of multiple linear regression?\n",
    "#### Answer:\n",
    "\n",
    "### 93. Explain gradient descent with respect to linear regression.\n",
    "#### Answer:\n",
    "\n",
    "### 94. Explain the bias-variance trade-off.\n",
    "#### Answer:\n",
    "\n",
    "### 95. Multiple linear regression (MLR) is a __________ type of statistical analysis.\n",
    "\n",
    "\t- univariate\n",
    "\t- bivariate\n",
    "\t- $ multivariate $\n",
    "    \n",
    "\n",
    "### 96. The following types of data can be used in MLR (choose all that apply)\n",
    "\n",
    "\t- $ Interval or higher dependent variable (DV)$\n",
    "\t- $ Interval or higher independent variables (IVs)$\n",
    "\t- $ Dichotomous IVs$\n",
    "    \n",
    "\n",
    "### 97. A linear regression (LR) analysis produces the equation Y = 0.4X + 3. This indicates that:\n",
    "\n",
    "\t- When Y = 0.4, X = 3\n",
    "\t- When Y = 0, X = 3\n",
    "\t- When X = 3, Y = 0.4\n",
    "\t- $ When X = 0, Y = 3 $\n",
    "    \n",
    "    \n",
    "### 98. A LR analysis produces the equation Y = -3.2X + 7. This indicates that:\n",
    "\n",
    "\t- $ A 1 unit increase in X results in a 3.2 unit decrease in Y.$\n",
    "\t- A 1 unit decrease in X results in a 3.2 unit decrease in Y.\n",
    "\t- A 1 unit increase in X results in a 3.2 unit increase in Y.\n",
    "\t- An X value of 0 would would increase Y by 7.\n",
    "    \n",
    "    \n",
    "### 99. The main purpose(s) of (LR) is/are (choose all that apply):\n",
    "\n",
    "\t- $ Predicting one variable on the basis of another$\n",
    "\t- $ Explaining one variable in terms of another$\n",
    "\t- Describing the relationship between one variable and another\n",
    "\t- Exploring the relationship between one variable and another\n",
    "    \n",
    "    \n",
    "### 100 When writing regression formulae, which of the following refers to the predicted value on the dependent variable (DV)?\n",
    "\n",
    "\t- Y\n",
    "\t- $ Y (hat)$\n",
    "\t- X\n",
    "\t- X (hat)\n",
    "\t- a\n",
    "    \n",
    "\n",
    "### 101. The major conceptual limitation of all regression techniques is that one can only ascertain relationships, but never be sure about underlying causal mechanism.\n",
    "\n",
    "\t- $ True$\n",
    "\t- False\n",
    "    \n",
    "\n",
    "### 102. In MLR, the square of the multiple correlation coefficient or R2 is called the\n",
    "\n",
    "\t- $ Coefficient of determination$\n",
    "\t- Variance\n",
    "\t- Covariance\n",
    "\t- Cross-product\n",
    "\t- Big R\n",
    "    \n",
    "\n",
    "### 103. In MLR, a residual is the difference between the predicted Y and actual Y values.\n",
    "\n",
    "\t- $ True$\n",
    "\t- False\n",
    "    \n",
    "    \n",
    "### 104. Shared and unique variance among multiple variables can be represented by a diagram that includes overlapping circles. This is referred to as a:\n",
    "\n",
    "\t- Homogeneity diagram\n",
    "\t- 3-way scatterplot\n",
    "\t- $ Venn diagram (2 circles) or Ballantine diagram (3 or more circles)$\n",
    "\t- Pie chart\n",
    "\t- Path diagram\n",
    "    \n",
    "### 105. In an MLR, the r between the two IVs is 1. Therefore, R will equal the r between one of the IVs and the DV. (Hint: Draw a Venn Diagram.)\n",
    "\n",
    "\t- $ True $\n",
    "\t- False\n",
    "    \n",
    "\n",
    "### 106. In a MLR, if the two IVs are correlated with the DV and the two IVs are correlated with one another, the rps (partial correlations) will be _______ in magnitude than the rs (Hint: Draw a Venn Diagram.)\n",
    "\n",
    "\t- Equal\n",
    "\t- $ Smaller $\n",
    "\t- Larger\n",
    "\t- Impossible to tell\n",
    "    \n",
    "\n",
    "### 107. In MLR, the unique variance in the DV explained by a particular IV is estimated by its:\n",
    "\n",
    "\t- Zero-order correlation squared (r2)\n",
    "\t- Multiple correlation coefficient squared (R2)\n",
    "\t- $ Semi-partial correlation squared (sr2) $\n",
    "    \n",
    "### 108. Interaction effects can be tested in MLR by using IVs that represent:\n",
    "\n",
    "\t- Cross-products between the IVs and DV\n",
    "\t- $ Cross-products of IVs $\n",
    "\t- Semi-partial correlations squared (sr2)\n",
    "    \n",
    "### 109. A researcher wants to assess the extent to which social support from group members can explain changes in participants' mental health (MH) which is measured at the beginning and end of an intervention program. What MLR design could be used?\n",
    "\n",
    "\t- $ Hierarchical with pre-MH in Step 1 $\n",
    "\t- Hierarchical with cross-products of IVs in Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
